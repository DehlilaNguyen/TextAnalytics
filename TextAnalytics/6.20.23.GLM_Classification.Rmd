---
title: "Classification using GLM models"
author: "Dehlila Nguyen"
date: '2023-06-19'
output: github_document
---

```{r setup, include=FALSE, warning=FALSE, message=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

#### Text Classification using GLM (Generalized Linear Model) models. In this markdown, we will review the below regression models. 

1. Ridge Regression
2. Lasso Regression
3. Elastic Net Regression

**Regularization**
Linear regression algorithm works by selecting coefficients for each independent variable that minimizes a loss function. However, if the coefficients are large, they can lead to over-fitting on the training dataset, and such a model will not generalize well on the unseen test data. To overcome this shortcoming, we'll do regularization, which penalizes large coefficients. Regularization algorithms helps to include penalty.

**Ridge Regression**
Ridge regression is an extension of linear regression where the loss function is modified to minimize the complexity of the model. If used with the GLM, then it can be used for classification problems. Loss function modification is done by adding a penalty parameter (lambda) that is equivalent to the square of the magnitude of the coefficients.

- Loss function = OLS + alpha * summation (squared coefficient values)
- Ridge regression is also referred to as l2 regularization.
- GLM has a parameter called alpha. For ridge regression using GLM, the value of alpha is zero.

**Lasso Regression**
Lasso regression, or the Least Absolute Shrinkage and Selection Operator, is also a modification of linear regression. In lasso, the loss function is modified to minimize the complexity of the model by limiting the sum of the absolute values of the model coefficients (also called the l1-norm).

The loss function for lasso regression can be expressed as below:

Loss function = OLS + alpha * summation (absolute values of the magnitude of the coefficients)

In the above function, alpha is the penalty parameter we need to select. Using an l1-norm constraint forces some weight values to zero to allow other coefficients to take non-zero values.

A **receiver operating characteristic curve, or ROC curve**, is a graphical plot that illustrates the diagnostic ability of a binary classifier system as its discrimination threshold is varied.      

The ROC curve is the plot of the true positive rate (TPR) against the false positive rate (FPR), at various threshold settings.     

- Positive rate measures: Sensitivity, recall, hit rate, or true positive rate = (True Positive)/(Total Number of Possible Positives). Total number of possible positives means positives correctly detected as positive + Positive but detected as Negative (False Negatives)
- True negative rate: specificity, selectivity or true negative rate (TNR). (True Negative)/(Total Number of Possible Negatives). Denominator is True Negative + False Positive. 



```{r load the libraries}
library(readr)
library(tm)
library(stringr)
library(glmnet) # To fit GLM models 
library(Matrix) # To create sparse matrix for GLM 
library(pROC) # to create ROC object for plotting ROC curves 
library(ggplot2)
library(dplyr) 
```

#### Use read_csv function of readr to read the dataset 
```{r read data}
news <- readRDS("news.rds")
```

```{r text-preprocessing function}
# Takes tm corpus and a customWords character vector as input to 
text_pre_process <- function(corpus, customWords = c()) {
  corpus <- tm_map(corpus, tolower)
  corpus <- tm_map(corpus, removeNumbers)
  corpus <- tm_map(corpus, stripWhitespace)
  corpus <- tm_map(corpus, removeWords, customWords)
  corpus <- tm_map(corpus, removeWords, stopwords(kind = "en"))
  return(corpus)
}
```

```{r pre-process text using the text_pre_process function}
corpus <- Corpus(VectorSource(news$text))
corpus <- text_pre_process(corpus)
news$text <- corpus$content 
```


#### It is better to split the dataset equally among the labels for the training and test datasets.

```{r create training and test datasets}
set.seed(1234) 
train_test_vector <- sample(c(0,1), nrow(news), replace = T, prob = c(0.7, 0.3))
train_news <- news[train_test_vector == 0, ]
test_news <- news[train_test_vector == 1, ]
```


```{r Create Document - Term Matrix }
train_corpus <- Corpus(VectorSource(train_news$text))
train_dtm <- DocumentTermMatrix(train_corpus)
train_dtm <- as.matrix(train_dtm)
train_dtm <- Matrix(train_dtm, sparse = T)
train_dtm <- train_dtm[, sort(colnames(train_dtm))]
```


```{r glmnet modeling}
gc()
glm_model <- cv.glmnet(train_dtm, 
                       y = as.factor(train_news$label), 
                       alpha = 1, # LASSO regression, 0 for Ridge regression, Glmnet for 0-1 
                       family = "binomial", 
                       nfolds = 10, 
                       type.measure = "class")
```

#### Glm model plot interpretations 
- There are two vertical dotted lines on the plot. 
1. The left line carries a lambda value which minimizes the misclassification error (FP+FN)/(TP+TN+FP+FN). 
2. The second line represents the highest regularization value within one standard deviation of the minimal class error.   

- Model based on the first line is more accurate with the best penalty value while the second line converges more with minimal input values. 

```{r plot the glm train model}
plot(glm_model)
```


```{r make training set predictions}
train_prediction <- predict(glm_model, train_dtm, type = "class", 
                            s = glm_model$lambda.1se ) # lambda.lse is the second model lambda
train_auc <- roc(as.integer(as.factor(train_news$label)),
                 as.integer(as.factor(train_prediction)))

print(train_auc)
plot(train_auc)

table(as.integer(as.factor(train_news$label)), 
      as.integer(as.factor(train_prediction)))
```

#### test dtm is required to make test predictions. However, the new words are possible in the unseen documents. As the prediction GLM would not understand the unseen terms, they should be dropped from the test dtm object. 

```{r make test predictions }
test_corpus <- Corpus(VectorSource(test_news$text))
test_dtm <- DocumentTermMatrix(test_corpus)
terms <- colnames(train_dtm[ , which(!colnames(train_dtm) %in% colnames(test_dtm))])
test_matrix <- matrix(0, nrow = nrow(test_dtm), ncol = length(terms))
colnames(test_matrix) <- terms
rownames(test_matrix) <- rownames(test_dtm)
test_dtm <- as.DocumentTermMatrix(
  cbind(test_dtm[, which(colnames(test_dtm) %in% colnames(train_dtm))],
        test_matrix),
  weighting = weightTf
  )

test_dtm <- as.matrix(test_dtm)
test_dtm <- Matrix(test_dtm, sparse = T)
test_dtm <- test_dtm[, sort(colnames(test_dtm))]
```



```{r make test set predictions}

test_prediction <- predict(glm_model, test_dtm, type = "class", 
                            s = glm_model$lambda.min) 
test_auc <- roc(as.integer(as.factor(test_news$label)),
                 as.integer(as.factor(test_prediction)))

print(test_auc)
plot(train_auc, col = "blue", lty = 1)
plot(test_auc, add = TRUE, col = "red", lty = 2)

table(as.integer(as.factor(test_news$label)),
                 as.integer(as.factor(test_prediction)))
```

#### Finding the impactful words 
```{r impactful words}
glmnet_coefficients <- as.matrix(coef(glm_model, s = "lambda.min"))
glmnet_coefficients <- data.frame(words = row.names(glmnet_coefficients), 
                                  glmnet_coefficients = glmnet_coefficients[,1])
glmnet_coefficients <- glmnet_coefficients[order(
  glmnet_coefficients$glmnet_coefficients, decreasing = T), ]
glmnet_coefficients$words <- factor(glmnet_coefficients$words, 
                                    levels = unique(glmnet_coefficients$words))
summary(glmnet_coefficients$glmnet_coefficients)
```
#### Check how many coefficients have value greater than 0
```{r check the impactful words}
# Total number of coefficients. 
print(paste0("total words: ", length(glmnet_coefficients$glmnet_coefficients)))
print(paste0("Impactful words: ", length(subset(glmnet_coefficients$glmnet_coefficients, 
              glmnet_coefficients$glmnet_coefficients > 0))))
```

#### Density plot of the coefficient values. 
```{r glm coefficients density}
ggplot(data = glmnet_coefficients) + 
  geom_density(aes(x = glmnet_coefficients))
```

```{r top "n" impactful words }
glmnet_coefficients <- glmnet_coefficients %>% 
  arrange(desc(abs(glmnet_coefficients)))

glmnet_coefficients <- head(glmnet_coefficients, 20)

#ggplot(glmnet_coefficients) +
#  geom_segment(aes(x = glmnet_coefficients, y = words, yend = words), xend = 0, 
#               color = "blue") + 
#  geom_point(aes(x= glmnet_coefficients, y = words, color = glmnet_coefficients), size = 2.5 ) 
```

**GLM Summary for classification**
- Feature engineering: Create additional inputs for the number of characters of words per document to be used. 
- Tokenization: Using bi-grams and tri-grams could be beneficial. 
- Alpha penalty: Adjust the penalty parameter to balance the number of inputs and accuracy. 
- Prediction stacking and ensembling modeling: Combine other models such as Lasso + SVM. 
- After creating one final model, use it. With usage, the test data keeps increasing. Create a process to label the data and retrain the model. 